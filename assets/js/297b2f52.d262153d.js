"use strict";(self.webpackChunkbellplay_docs=self.webpackChunkbellplay_docs||[]).push([[7034],{6981:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>o,default:()=>u,frontMatter:()=>r,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"learning/tutorials/buildcorpus","title":"18. Audio corpora with SQL tables","description":"This tutorial demonstrates how to create an in-memory, queryable corpus of audio buffers by leveraging the createtable and querytable functions.","source":"@site/docs/learning/tutorials/buildcorpus.md","sourceDirName":"learning/tutorials","slug":"/learning/tutorials/buildcorpus","permalink":"/docs/learning/tutorials/buildcorpus","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":17,"frontMatter":{"sidebar_position":17,"title":"18. Audio corpora with SQL tables"},"sidebar":"tutorialSidebar","previous":{"title":"17. More Audio Features","permalink":"/docs/learning/tutorials/features"},"next":{"title":"19. Caching Data","permalink":"/docs/learning/tutorials/caching"}}');var s=n(4848),a=n(8453);const r={sidebar_position:17,title:"18. Audio corpora with SQL tables"},o="Audio corpora with SQL tables",l={},c=[];function d(e){const t={a:"a",code:"code",h1:"h1",header:"header",p:"p",pre:"pre",...(0,a.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(t.header,{children:(0,s.jsx)(t.h1,{id:"audio-corpora-with-sql-tables",children:"Audio corpora with SQL tables"})}),"\n",(0,s.jsxs)(t.p,{children:["This tutorial demonstrates how to create an in-memory, queryable corpus of audio buffers by leveraging the ",(0,s.jsx)(t.code,{children:"createtable"})," and ",(0,s.jsx)(t.code,{children:"querytable"})," functions.\nThese functions allow you to structure and filter lllls using ",(0,s.jsx)(t.a,{href:"https://www.sqlitetutorial.net/",children:"SQLite3"})," queries based on specific keys."]}),"\n",(0,s.jsxs)(t.p,{children:["We begin by importing an audio file and splitting it into short fixed-length segments. Each segment is then analyzed using the ",(0,s.jsx)(t.code,{children:"pitchmelodia"})," descriptor, which provides an estimation of predominant melody pitch and associated confidence values.\nThe results of this analysis are assembled into a structured table using ",(0,s.jsx)(t.code,{children:"createtable"}),"."]}),"\n",(0,s.jsxs)(t.p,{children:["Each element in the input data passed to ",(0,s.jsx)(t.code,{children:"createtable"})," should be structured as a list of key-value pairs, where each key corresponds to a column name in the resulting table and each value is the corresponding data entry.\nFor example:"]}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-bell",metastring:'title="expected structure for each data item"',children:"[\n    [ <key_1> <value_1> ]\n    [ <key_2> <value_2> ]\n    ...\n    [ <key_N> <value_N> ]\n]\n"})}),"\n",(0,s.jsx)(t.p,{children:"This format ensures that the resulting table can be queried using standard SQL-style syntax, with each key becoming a column in the table schema."}),"\n",(0,s.jsxs)(t.p,{children:["Once the table is created, we can query it using ",(0,s.jsx)(t.code,{children:"querytable"}),", selecting only segments that meet certain criteria\u2014here, those with a pitch confidence greater than ",(0,s.jsx)(t.code,{children:"0.01"}),"\u2014and ordering them by ",(0,s.jsx)(t.a,{href:"https://en.wikipedia.org/wiki/Pitch_class",children:"pitch class"})," (pitch modulo 1200)."]}),"\n",(0,s.jsx)(t.p,{children:"Finally, the selected segments are rendered back as symbolic notes, placed at regular temporal intervals and randomized in the stereo field."}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-bell",metastring:'title="audio_corpora_with_sql_tables.bell" showLineNumbers',children:"## Import an audio file into a buffer\n$buffer = importaudio('trumpet.wav');\n## Split the buffer into fixed-length segments of 100 ms\n$segments = $buffer.splitbuf(@split 100);\n## Analyze each segment with the 'pitchmelodia' descriptor and collect the results\n$corpus = for $seg in $segments collect $seg.analyze(pitchmelodia());\n## Create an in-memory SQL table named 'corpus' from the analysis results\ncreatetable(\n    @data $corpus @name 'corpus' \n);\n## Query the table to select segments with high pitch confidence,\n## ordered by pitch class (pitch modulo 1200)\n$results = querytable('SELECT * FROM corpus WHERE pitchmelodia_confidence > 0.01 ORDER BY (pitchmelodia % 1200)');\n## Initialize onset time for transcription\n$onset = 0;\n## Transcribe each selected segment with symbolic pitch and random panning\nfor $seg in $results do (\n    $seg.transcribe(\n        @onset $onset\n        @pitchkey 'pitchmelodia' \n        @pan rand() \n    );\n    $onset += 50\n    ## Increment onset time for next segment\n    \n);\n## Trigger rendering\nrender(@play 1)\n"})})]})}function u(e={}){const{wrapper:t}={...(0,a.R)(),...e.components};return t?(0,s.jsx)(t,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},8453:(e,t,n)=>{n.d(t,{R:()=>r,x:()=>o});var i=n(6540);const s={},a=i.createContext(s);function r(e){const t=i.useContext(a);return i.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function o(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:r(e.components),i.createElement(a.Provider,{value:t},e.children)}}}]);