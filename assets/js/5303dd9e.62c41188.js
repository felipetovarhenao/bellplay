"use strict";(self.webpackChunkbellplay_docs=self.webpackChunkbellplay_docs||[]).push([[3646],{792:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>o,default:()=>m,frontMatter:()=>a,metadata:()=>i,toc:()=>l});const i=JSON.parse('{"id":"learning/examples/markov","title":"6. Markov Music Generation","description":"This script illustrates how to construct and use an nth-order Markov model from MIDI data in bellplay~ for generative music.","source":"@site/docs/learning/examples/markov.md","sourceDirName":"learning/examples","slug":"/learning/examples/markov","permalink":"/docs/learning/examples/markov","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":5,"frontMatter":{"sidebar_position":5,"title":"6. Markov Music Generation"},"sidebar":"tutorialSidebar","previous":{"title":"5. Glissando texture","permalink":"/docs/learning/examples/gliss"},"next":{"title":"7. MIDI Retuning","permalink":"/docs/learning/examples/midiretuning"}}');var r=t(4848),s=t(8453);const a={sidebar_position:5,title:"6. Markov Music Generation"},o="Markov Music Generation",c={},l=[];function d(e){const n={a:"a",code:"code",em:"em",h1:"h1",header:"header",p:"p",pre:"pre",strong:"strong",...(0,s.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"markov-music-generation",children:"Markov Music Generation"})}),"\n",(0,r.jsxs)(n.p,{children:["This script illustrates how to construct and use an nth-order ",(0,r.jsx)(n.a,{href:"https://en.wikipedia.org/wiki/Markov_model",children:"Markov model"})," from MIDI data in ",(0,r.jsx)(n.strong,{children:"bellplay~"})," for generative music."]}),"\n",(0,r.jsxs)(n.p,{children:["It begins by importing a MIDI file as a list of note events, where each event includes keys like ",(0,r.jsx)(n.code,{children:"'pitch'"})," and ",(0,r.jsx)(n.code,{children:"'onset'"}),".\nThese events are then grouped into overlapping pairs.\nFor each pair, the pitch of the first event and the time difference (in milliseconds) between the two onsets are extracted and rounded.\nThese ",(0,r.jsx)(n.em,{children:"pitch-timestep"})," pairs form the training data for a Markov model, which is trained using ",(0,r.jsx)(n.code,{children:"seq2markov"})," with order ",(0,r.jsx)(n.code,{children:"1"}),"."]}),"\n",(0,r.jsxs)(n.p,{children:["Once trained, the Markov model generates a new sequence of ",(0,r.jsx)(n.code,{children:"[<pitch> <timestep>]"})," tuples via ",(0,r.jsx)(n.code,{children:"markov2seq"}),".\nThis generated sequence is rendered as audio using the ",(0,r.jsx)(n.code,{children:"ezsampler"})," function, where the onset time is computed by accumulating the timestep values."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bell",metastring:'title="markov_music_generation.bell" showLineNumbers',children:"## Load a MIDI file as list of note events\n$events = importmidi('joplin.mid');\n## Group MIDI events into overlapping pairs: (event\u2081, event\u2082), (event\u2082, event\u2083), ...\n$pairs = group(\n    @llll $events\n    @modulos 2\n    @overlap 1\n);\n## Convert each event pair into a Markov training state\n$trainseq = for $pair in $pairs with @unwrap 1 collect (\n    ## Extract the two consecutive events from the pair\n    $event1 = $pair:1;\n    $event2 = $pair:2;\n    ## Compute the time delta between the two events\n    $timestep = $event2.getkey('onset') - $event1.getkey('onset');\n    ## Construct a training tuple: (pitch, rounded timestep in milliseconds)\n    [$event1.getkey('pitch') round($timestep)] \n);\n## Train a first-order Markov model from the training sequence\n$matrix = seq2markov(@sequence $trainseq @order 1);\n## Generate a random sequence of (pitch, timestep) tuples from the trained model\n$seq = markov2seq(\n    ## the trained Markov transition matrix\n    @matrix $matrix\n    ## initial state (optional): first item from training sequence\n    @start $trainseq:1\n    ## maximum number of steps in generated sequence\n    @maxlength 250\n    ## reset transition to random state if terminal state is reached\n    @autoclear 1\n);\n## Initialize onset variable\n$t = 0;\n## Iterate over generated events and render them using sampling\nfor $event in $seq with @unwrap 1 do (\n    ## extract pitch and time increment\n    $pitch = $event:1;\n    $timestep = $event:2;\n    ## Synthesize the pitch using a sampler, scheduling it at time $t\n    ezsampler(@pitch $pitch).transcribe(@onset $t);\n    ## Increment the time by the event's timestep\n    $t += $timestep\n);\n## Trigger rendering and playback\nrender(@play 1)\n"})})]})}function m(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>a,x:()=>o});var i=t(6540);const r={},s=i.createContext(r);function a(e){const n=i.useContext(s);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:a(e.components),i.createElement(s.Provider,{value:n},e.children)}}}]);