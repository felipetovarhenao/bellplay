"use strict";(self.webpackChunkbellplay_docs=self.webpackChunkbellplay_docs||[]).push([[4426],{7632:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>d,contentTitle:()=>o,default:()=>a,frontMatter:()=>l,metadata:()=>s,toc:()=>t});const s=JSON.parse('{"id":"reference/audio-analysis/pitchmelodia","title":"pitchmelodia","description":"pitchmelodia","source":"@site/docs/reference/audio-analysis/pitchmelodia.md","sourceDirName":"reference/audio-analysis","slug":"/reference/audio-analysis/pitchmelodia","permalink":"/bellplay/docs/reference/audio-analysis/pitchmelodia","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"hide_title":true},"sidebar":"tutorialSidebar","previous":{"title":"onsets","permalink":"/bellplay/docs/reference/audio-analysis/onsets"},"next":{"title":"pitchyin","permalink":"/bellplay/docs/reference/audio-analysis/pitchyin"}}');var c=i(4848),r=i(8453);const l={hide_title:!0},o=void 0,d={},t=[{value:"<code>pitchmelodia</code>",id:"pitchmelodia",level:2}];function h(e){const n={code:"code",em:"em",h2:"h2",hr:"hr",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,c.jsxs)(c.Fragment,{children:[(0,c.jsx)(n.h2,{id:"pitchmelodia",children:(0,c.jsx)(n.code,{children:"pitchmelodia"})}),"\n",(0,c.jsx)(n.pre,{children:(0,c.jsx)(n.code,{className:"language-bell",children:"pitchmelodia(\n    @binresolution 10\n    @filteriterations 3\n    @framesize 2048\n    @guessunvoiced 0\n    @harmonicweight 0.8000\n    @hopsize 1024\n    @magnitudecompression 1\n    @magnitudethreshold 40\n    @maxfrequency 20000\n    @minduration 100\n    @minfrequency 40\n    @numberharmonics 20\n    @peakdistributionthreshold 0.9000\n    @peakframethreshold 0.9000\n    @pitchcontinuity 27.5625\n    @referencefrequency 55\n    @samplerate 44100\n    @timecontinuity 100\n    @polyphonic 0\n    @voicevibrato 0\n    @voicingtolerance 0.2000\n    @mode 0\n) -> llll\n"})}),"\n",(0,c.jsxs)(n.p,{children:["Audio descriptor to estimate the fundamental frequency corresponding to the melody of a monophonic music signal based on the MELODIA algorithm. While the algorithm is originally designed to extract the predominant melody from polyphonic music, this implementation is adapted for monophonic signals. The approach is based on the creation and characterization of pitch contours, time continuous sequences of pitch candidates grouped using auditory streaming cues. It is strongly advised to use the default parameter values which are optimized for this task, except for ",(0,c.jsx)(n.code,{children:"@minfrequency"})," and ",(0,c.jsx)(n.code,{children:"@maxfrequency"}),", which will be context-dependent. See ",(0,c.jsx)(n.code,{children:"analyze"}),"."]}),"\n",(0,c.jsx)(n.p,{children:"The resulting buffer will be updated with the following keys:"}),"\n",(0,c.jsxs)(n.ul,{children:["\n",(0,c.jsx)(n.li,{children:(0,c.jsx)(n.code,{children:"'pitchmelodia'"})}),"\n",(0,c.jsx)(n.li,{children:(0,c.jsx)(n.code,{children:"'pitchmelodia_confidence'"})}),"\n"]}),"\n",(0,c.jsx)(n.p,{children:"Which can be applied and accessed like so:"}),"\n",(0,c.jsx)(n.pre,{children:(0,c.jsx)(n.code,{className:"language-bell",metastring:"showLineNumbers",children:"$buf = $buf.analyze(pitchmelodia());\n$pitchmelodia = $buf.getkey('pitchmelodia');\n$pitchmelodia_confidence = $buf.getkey('pitchmelodia_confidence')\n"})}),"\n",(0,c.jsx)(n.hr,{}),"\n",(0,c.jsxs)(n.p,{children:[(0,c.jsx)(n.strong,{children:"Arguments"}),":"]}),"\n",(0,c.jsxs)(n.ul,{children:["\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.code,{children:"@binresolution"})," [",(0,c.jsx)(n.em,{children:(0,c.jsx)(n.strong,{children:"int"})}),"]: salience function bin resolution, in cents."]}),"\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.code,{children:"@filteriterations"})," [",(0,c.jsx)(n.em,{children:(0,c.jsx)(n.strong,{children:"int"})}),"]: number of iterations for the octave errors / pitch outlier filtering process."]}),"\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.code,{children:"@framesize"})," [",(0,c.jsx)(n.em,{children:(0,c.jsx)(n.strong,{children:"int"})}),"]: frame size for computing pitch salience."]}),"\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.code,{children:"@guessunvoiced"})," [",(0,c.jsx)(n.em,{children:(0,c.jsx)(n.strong,{children:"int"})}),"]: estimate pitch for non-voiced segments.","\n",(0,c.jsxs)(n.ul,{children:["\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.code,{children:"0"}),": off"]}),"\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.code,{children:"1"}),": on"]}),"\n"]}),"\n"]}),"\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.code,{children:"@harmonicweight"})," [",(0,c.jsx)(n.em,{children:(0,c.jsx)(n.strong,{children:"int/float"})}),"]: weight decay ratio between two consequent harmonics. Use ",(0,c.jsx)(n.code,{children:"1"})," for no decay."]}),"\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.code,{children:"@hopsize"})," [",(0,c.jsx)(n.em,{children:(0,c.jsx)(n.strong,{children:"int"})}),"]: hop size with which the pitch salience function was computed."]}),"\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.code,{children:"@magnitudecompression"})," [",(0,c.jsx)(n.em,{children:(0,c.jsx)(n.strong,{children:"int"})}),"]: magnitude compression parameter for the salience function.","\n",(0,c.jsxs)(n.ul,{children:["\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.code,{children:"0"}),": maximum compression"]}),"\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.code,{children:"1"}),": no compression"]}),"\n"]}),"\n"]}),"\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.code,{children:"@magnitudethreshold"})," [",(0,c.jsx)(n.em,{children:(0,c.jsx)(n.strong,{children:"int"})}),"]: spectral peak magnitude threshold, in decibels."]}),"\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.code,{children:"@maxfrequency"})," [",(0,c.jsx)(n.em,{children:(0,c.jsx)(n.strong,{children:"int/float"})}),"]: the maximum allowed frequency for salience function peaks."]}),"\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.code,{children:"@minduration"})," [",(0,c.jsx)(n.em,{children:(0,c.jsx)(n.strong,{children:"int"})}),"]: the minimum allowed contour duration."]}),"\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.code,{children:"@minfrequency"})," [",(0,c.jsx)(n.em,{children:(0,c.jsx)(n.strong,{children:"int/float"})}),"]: the minimum allowed frequency for salience function peaks."]}),"\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.code,{children:"@numberharmonics"})," [",(0,c.jsx)(n.em,{children:(0,c.jsx)(n.strong,{children:"int"})}),"]: number of considered harmonics."]}),"\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.code,{children:"@peakdistributionthreshold"})," [",(0,c.jsx)(n.em,{children:(0,c.jsx)(n.strong,{children:"int/float"})}),"]: allowed deviation below the peak salience mean over all frames."]}),"\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.code,{children:"@peakframethreshold"})," [",(0,c.jsx)(n.em,{children:(0,c.jsx)(n.strong,{children:"int/float"})}),"]: per-frame salience threshold factor."]}),"\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.code,{children:"@pitchcontinuity"})," [",(0,c.jsx)(n.em,{children:(0,c.jsx)(n.strong,{children:"int/float"})}),"]: maximum allowed pitch change during 1 ms time period, in cents."]}),"\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.code,{children:"@referencefrequency"})," [",(0,c.jsx)(n.em,{children:(0,c.jsx)(n.strong,{children:"int/float"})}),"]: the reference frequency to cent conversion corresponding to the 0th cent bin."]}),"\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.code,{children:"@samplerate"})," [",(0,c.jsx)(n.em,{children:(0,c.jsx)(n.strong,{children:"int"})}),"]: the sampling rate of the audio signal."]}),"\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.code,{children:"@timecontinuity"})," [",(0,c.jsx)(n.em,{children:(0,c.jsx)(n.strong,{children:"int"})}),"]: maximum allowed gap duration for a pitch contour, in milliseconds."]}),"\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.code,{children:"@polyphonic"})," [",(0,c.jsx)(n.em,{children:(0,c.jsx)(n.strong,{children:"int"})}),"]: optimize for polyphonic buffer.","\n",(0,c.jsxs)(n.ul,{children:["\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.code,{children:"0"}),": off"]}),"\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.code,{children:"1"}),": on"]}),"\n"]}),"\n"]}),"\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.code,{children:"@voicevibrato"})," [",(0,c.jsx)(n.em,{children:(0,c.jsx)(n.strong,{children:"int"})}),"]: detect voice vibrato, when ",(0,c.jsx)(n.code,{children:"@polyphonic"})," is ",(0,c.jsx)(n.code,{children:"1"}),".","\n",(0,c.jsxs)(n.ul,{children:["\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.code,{children:"0"}),": off"]}),"\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.code,{children:"1"}),": on"]}),"\n"]}),"\n"]}),"\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.code,{children:"@voicingtolerance"})," [",(0,c.jsx)(n.em,{children:(0,c.jsx)(n.strong,{children:"int/float"})}),"]: voicing tolerance between -1 and 1.4, when ",(0,c.jsx)(n.code,{children:"@polyphonic"})," is ",(0,c.jsx)(n.code,{children:"1"}),"."]}),"\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.code,{children:"@mode"})," [",(0,c.jsx)(n.em,{children:(0,c.jsx)(n.strong,{children:"int"})}),"]: analysis mode.","\n",(0,c.jsxs)(n.ul,{children:["\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.code,{children:"0"}),": global"]}),"\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.code,{children:"1"}),": time series"]}),"\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.code,{children:"2"}),": time-tagged time series"]}),"\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.code,{children:"3"}),": buffer"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,c.jsx)(n.hr,{}),"\n",(0,c.jsx)(n.p,{children:(0,c.jsx)(n.strong,{children:"Output"})}),"\n",(0,c.jsxs)(n.p,{children:["pitchmelodia descriptor [",(0,c.jsx)(n.strong,{children:(0,c.jsx)(n.em,{children:"llll"})}),"]"]})]})}function a(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,c.jsx)(n,{...e,children:(0,c.jsx)(h,{...e})}):h(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>l,x:()=>o});var s=i(6540);const c={},r=s.createContext(c);function l(e){const n=s.useContext(r);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(c):e.components||c:l(e.components),s.createElement(r.Provider,{value:n},e.children)}}}]);