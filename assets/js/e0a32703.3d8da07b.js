"use strict";(self.webpackChunkbellplay_docs=self.webpackChunkbellplay_docs||[]).push([[954],{71563:e=>{e.exports=JSON.parse('{"tag":{"label":"pitchdiff","permalink":"/docs/tags/pitchdiff","allTagsPath":"/docs/tags","count":6,"items":[{"id":"learning/examples/resynthesis","title":"1. Audio Resynthesis","description":"A simple demonstration of granular quasi-resynthesis via partial tracks, where an sound is used to guide the behavior of sinusoidal grains.","permalink":"/docs/learning/examples/resynthesis"},{"id":"learning/tutorials/analysismodes","title":"16. Audio Descriptor Modes","description":"When analyzing buffers, we can specify the output format for many of the available audio descriptors.","permalink":"/docs/learning/tutorials/analysismodes"},{"id":"learning/tutorials/features","title":"17. More Audio Features","description":"This tutorial provides an additional example for using buffer analysis features for audio processing.","permalink":"/docs/learning/tutorials/features"},{"id":"learning/tutorials/caching","title":"19. Caching Data","description":"In bellplay~, computation-heavy operations such as building large corpora, analyzing lots of audio data, and more, can be take a very long time, thus making it more tedious to experiment with our scripts every time we run them.","permalink":"/docs/learning/tutorials/caching"},{"id":"learning/tutorials/kdtree","title":"23. Feature-driven Sampling","description":"This tutorial shows how to build k-dimensional trees to efficiently perform feature-based search on buffers.","permalink":"/docs/learning/tutorials/kdtree"},{"id":"learning/examples/midiretuning","title":"7. MIDI Retuning","description":"An example of JI-based retuning of MIDI events.","permalink":"/docs/learning/examples/midiretuning"}],"unlisted":false}}')}}]);