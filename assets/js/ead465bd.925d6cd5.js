"use strict";(self.webpackChunkbellplay_docs=self.webpackChunkbellplay_docs||[]).push([[2336],{8240:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>o,default:()=>h,frontMatter:()=>s,metadata:()=>i,toc:()=>d});const i=JSON.parse('{"id":"learning/tutorials/kdtree","title":"23. Feature-driven Sampling","description":"This tutorial shows how to build k-dimensional trees to efficiently perform feature-based search on buffers.","source":"@site/docs/learning/tutorials/kdtree.md","sourceDirName":"learning/tutorials","slug":"/learning/tutorials/kdtree","permalink":"/docs/learning/tutorials/kdtree","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":22,"frontMatter":{"sidebar_position":22,"title":"23. Feature-driven Sampling"},"sidebar":"tutorialSidebar","previous":{"title":"22. Importing MIDI","permalink":"/docs/learning/tutorials/importingmidi"},"next":{"title":"24. Score Formatting and Appearance","permalink":"/docs/learning/tutorials/scoreconfig"}}');var r=t(4848),a=t(8453);const s={sidebar_position:22,title:"23. Feature-driven Sampling"},o="Feature-driven Sampling",c={},d=[];function l(e){const n={a:"a",code:"code",h1:"h1",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",...(0,a.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"feature-driven-sampling",children:"Feature-driven Sampling"})}),"\n",(0,r.jsxs)(n.p,{children:["This tutorial shows how to build ",(0,r.jsx)(n.a,{href:"https://en.wikipedia.org/wiki/K-d_tree",children:"k-dimensional trees"})," to efficiently perform feature-based search on buffers.\nIn this case, we use it to find the best buffer match for each pitch value in a MIDI file.\nIn this tutorial, we do the following:"]}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsx)(n.li,{children:"Slice a trumpet buffer into multiple onset-based segments, and analyze each."}),"\n",(0,r.jsx)(n.li,{children:"Build a tree based on those segments, using pitch as the search metric/feature."}),"\n",(0,r.jsx)(n.li,{children:"Load a MIDI file as a list of events."}),"\n",(0,r.jsx)(n.li,{children:"For each event, we search the tree for the best pitch-wise buffer match."}),"\n",(0,r.jsx)(n.li,{children:"We get the deviation between the matched buffer segment and the target pitch."}),"\n",(0,r.jsx)(n.li,{children:"We transcribe the buffer match, using the MIDI event's onset and apply the pitch deviation."}),"\n",(0,r.jsx)(n.li,{children:"Finally, we render the entire sequence and apply post-rendering reverb and gain normalization."}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bell",metastring:'title="feature-driven_sampling.bell" showLineNumbers',children:"## load source buffer\n$source = importaudio('trumpet.wav');\n## perform onset detection analysis on buffer\n$source = $source.analyze(onsets());\n## get list of transient-based onset times\n$markers = $source.getkey('onsets');\n## split buffers into different segments, based on markers\n$segments = $source.splitbuf(@split $markers @mode 2);\n## initialize data\n$data = null;\n## iterate through segments to filter unpitched ones\n$segments = for $seg in $segments collect (\n    ## analyze current segment for pitch detection\n    $seg = $seg.analyze(pitchmelodia());\n    ## get detected results\n    $pitch = $seg.getkey('pitchmelodia');\n    ## reject segments with no detected pitch\n    if $pitch > 0 then (\n        ## append pitch as list to data list\n        $data _= [$pitch];\n        ## return segment to collect\n        $seg\n    ) \n);\n## create a k-dimensional tree on segments' pitch values.\n$tree = createtree($data);\n## import MIDI file\n$events = importmidi('bach.mid');\n## MIDI output speed\n$speed = 1.33;\n## tolerance for cent deviation when searching for pitch matches in tree\n$tolerance = 300;\n## gain envelope for every buffer match\n$gainenv = [0 0 0] [1 1 0.25] [10 0 -.25];\n## iterate through MIDI events\nfor $event in $events do (\n    ## get pitch, onset, and duration info from event\n    $pitch = $event.getkey('pitch');\n    $onset = $event.getkey('onset');\n    $duration = $event.getkey('duration');\n    ## query tree for index of nearest pitch in tree.\n    $matchindex = querytree($tree, $pitch + rand(-$tolerance/2, $tolerance/2));\n    ## extract segment based on match's index\n    $match = $segments:$matchindex;\n    ## get cents deviation between target pitch and buffer match\n    $detune = pitchdiff($match.getkey('pitchmelodia'), $pitch);\n    ## adjust duration to make up for resampling-based detuning\n    $duration /= c2r($detune);\n    ## modify match's duration via lambda function\n    $match = $match.mapkey('duration', $x -^ $duration -> min($x, $duration));\n    ## transcribe match using MIDI event's onset and pitch deviation\n    $match.transcribe(\n        @onset $onset / $speed\n        @detune $detune\n        @gain $gainenv\n        @pan rand() \n        @pitchkey 'pitchmelodia' \n    ) \n);\n## trigger rendering\nrender(\n    @play 1 @process (\n        ## apply reverb and normalization\n        freeverb() normalize() \n    ) \n)\n"})})]})}function h(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(l,{...e})}):l(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>s,x:()=>o});var i=t(6540);const r={},a=i.createContext(r);function s(e){const n=i.useContext(a);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:s(e.components),i.createElement(a.Provider,{value:n},e.children)}}}]);