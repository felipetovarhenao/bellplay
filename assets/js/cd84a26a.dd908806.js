"use strict";(self.webpackChunkbellplay_docs=self.webpackChunkbellplay_docs||[]).push([[9248],{6031:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>u,contentTitle:()=>s,default:()=>c,frontMatter:()=>o,metadata:()=>i,toc:()=>l});const i=JSON.parse('{"id":"learning/tutorials/features","title":"17. More Audio Features","description":"This tutorial provides an additional example for using buffer analysis features for audio processing.","source":"@site/docs/learning/tutorials/features.md","sourceDirName":"learning/tutorials","slug":"/learning/tutorials/features","permalink":"/docs/learning/tutorials/features","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":16,"frontMatter":{"sidebar_position":16,"title":"17. More Audio Features"},"sidebar":"tutorialSidebar","previous":{"title":"16. Audio Descriptor Modes","permalink":"/docs/learning/tutorials/analysismodes"},"next":{"title":"18. Audio Corpora","permalink":"/docs/learning/tutorials/corpus"}}');var a=t(4848),r=t(8453);const o={sidebar_position:16,title:"17. More Audio Features"},s="More Audio Features",u={},l=[];function d(e){const n={code:"code",h1:"h1",header:"header",p:"p",pre:"pre",...(0,r.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.header,{children:(0,a.jsx)(n.h1,{id:"more-audio-features",children:"More Audio Features"})}),"\n",(0,a.jsx)(n.p,{children:"This tutorial provides an additional example for using buffer analysis features for audio processing.\nParticularly, it shows how to perform targeted transposition on an audio buffer, such that it fits a specific pitch class collection."}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bell",metastring:'title="more_audio_features.bell" showLineNumbers',children:"## path to built-in audio file\n$path = 'singing.wav';\n## uncomment the line below\ud83d\udc47 to use an audio file path of your choosing\n## $path = \"/path/to/your/file.wav\"\n## import audio file as buffer\n$buffer = importaudio($path);\n## grain duration\n$dur = 100;\n## modify buffer duration \u2014 REMEMBER: this is a lazy modification. It only takes effect until the buffer is transcribed and/or processed.\n$buffer = $buffer.setkey('duration', $dur);\n## initialize offset variable\n$offset = 0;\n## get the duration of the underlying buffer source (i.e., the total file duration)\n$maxduration = $buffer.getkey('source_end');\n## audio descriptor for pitch analysis\n$descriptor = pitchmelodia();\n## start loop until we reach the end of the buffer's original source (i.e., the imported file)\nwhile $offset < $maxduration - $dur do (\n    ## change the buffer's offset key and store in grain variable\n    $grain = $buffer.setkey('offset', $offset);\n    ## analyze grain\n    $grain = $grain.analyze( \n    ## pitch analysis, in midicents\n    $descriptor);\n    ## extract pitch analysis value\n    $pitch = $grain.getkey('pitchmelodia');\n    ## this function gives us the amount of detuning in cents we need to apply to a grain in order to reach a given pitch collection.\n    ## In this case, we specify the collection as pitch classes, representing a diminished 7th chord.\n    $detune = $pitch.pitchdiff(0 3 6 9);\n    ## transcribe grain, and apply resampling-based detuning\n    $grain.transcribe(\n        ## keep the same onset as the original file\n        @onset $offset\n        ## pass detuning amount in cents\n        @detune $detune\n        ## generate a numeric list that describes a hanning-like amplitude window and use as gain\n        @gain hanning() \n        ## we want to use the pitch information as\n        @pitchkey 'pitchmelodia' \n    );\n    ## increment offset by 1/3 of the grain duration to have an overlap of 3 grains at all times\n    $offset += $dur / 3\n);\n## render all grains and normalize output to be -6dB \nrender(\n    @play 1 @process normalize(-6) \n)\n"})})]})}function c(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(d,{...e})}):d(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>o,x:()=>s});var i=t(6540);const a={},r=i.createContext(a);function o(e){const n=i.useContext(r);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function s(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:o(e.components),i.createElement(r.Provider,{value:n},e.children)}}}]);