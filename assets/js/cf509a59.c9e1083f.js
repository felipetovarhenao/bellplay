"use strict";(self.webpackChunkbellplay_docs=self.webpackChunkbellplay_docs||[]).push([[8779],{28453:(e,n,i)=>{i.d(n,{R:()=>s,x:()=>o});var r=i(96540);const t={},a=r.createContext(t);function s(e){const n=r.useContext(a);return r.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:s(e.components),r.createElement(a.Provider,{value:n},e.children)}},97143:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>p,frontMatter:()=>s,metadata:()=>r,toc:()=>c});const r=JSON.parse('{"id":"learning/examples/resynthesis","title":"1. Audio Resynthesis","description":"A simple demonstration of granular quasi-resynthesis via partial tracks, where an sound is used to guide the behavior of sinusoidal grains.","source":"@site/docs/learning/examples/resynthesis.md","sourceDirName":"learning/examples","slug":"/learning/examples/resynthesis","permalink":"/docs/learning/examples/resynthesis","draft":false,"unlisted":false,"tags":[{"inline":true,"label":"buf2ptracks","permalink":"/docs/tags/buf-2-ptracks"},{"inline":true,"label":"c2r","permalink":"/docs/tags/c-2-r"},{"inline":true,"label":"cycle","permalink":"/docs/tags/cycle"},{"inline":true,"label":"f2mc","permalink":"/docs/tags/f-2-mc"},{"inline":true,"label":"getkey","permalink":"/docs/tags/getkey"},{"inline":true,"label":"importaudio","permalink":"/docs/tags/importaudio"},{"inline":true,"label":"normalize","permalink":"/docs/tags/normalize"},{"inline":true,"label":"pitchdiff","permalink":"/docs/tags/pitchdiff"},{"inline":true,"label":"rand","permalink":"/docs/tags/rand"},{"inline":true,"label":"random","permalink":"/docs/tags/random"},{"inline":true,"label":"render","permalink":"/docs/tags/render"},{"inline":true,"label":"transcribe","permalink":"/docs/tags/transcribe"}],"version":"current","sidebarPosition":0,"frontMatter":{"sidebar_position":0,"title":"1. Audio Resynthesis","tags":["buf2ptracks","c2r","cycle","f2mc","getkey","importaudio","normalize","pitchdiff","rand","random","render","transcribe"]},"sidebar":"tutorialSidebar","previous":{"title":"24. Score Formatting and Appearance","permalink":"/docs/learning/tutorials/scoreconfig"},"next":{"title":"2. Basic Granulation","permalink":"/docs/learning/examples/basicgranulation"}}');var t=i(74848),a=i(28453);const s={sidebar_position:0,title:"1. Audio Resynthesis",tags:["buf2ptracks","c2r","cycle","f2mc","getkey","importaudio","normalize","pitchdiff","rand","random","render","transcribe"]},o="Audio Resynthesis",l={},c=[];function d(e){const n={code:"code",h1:"h1",header:"header",p:"p",pre:"pre",...(0,a.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"audio-resynthesis",children:"Audio Resynthesis"})}),"\n",(0,t.jsx)(n.p,{children:"A simple demonstration of granular quasi-resynthesis via partial tracks, where an sound is used to guide the behavior of sinusoidal grains.\nIt focuses on extracting partials trakcs, mapping them onto synthesis parameters, and rebuilding the sound with flexible control over pitch, register, and time."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bell",metastring:'title="audio_resynthesis.bell" showLineNumbers',children:"## Import an audio buffer from the file 'poem.wav'\n$b = importaudio('poem.wav');\n## Transcribe the original audio file for reference\n$b.transcribe(@gain 0.5);\n## Define hop size for spectral analysis in samples\n$hopsize = 512;\n## Perform partial tracking analysis with a magnitude threshold\n$analysis = $b.buf2ptracks(@magnitudethreshold 0.05 @hopsize $hopsize);\n## Convert hop size to milliseconds based on the sample rate\n$incr = $hopsize * 1000 / $b.getkey('sr');\n## Extract frequency and magnitude data from the analysis\n$freqs = $analysis.getkey('frequencies');\n$mags = $analysis.getkey('magnitudes');\n## Define overlap factor for randomized timing variations\n$overlap = 4;\n## Define pitch classes for retuning\n$pcs = 0 2 3 5 7 8 10;\n## Loop through frequency and magnitude data\nfor $freq $addr in $freqs, $mag in $mags with @maxdepth -1 do (\n    ## Ensure the frequency is valid (greater than 0)\n    if $freq > 0 then (\n        ## Determine the onset frame index\n        $frame = $addr:2;\n        ## Compute the onset time in milliseconds\n        $onset = ($frame - 1) * $incr;\n        ## Randomly select a duration for the event\n        $dur = rand(100, 500);\n        ## Apply jitter to onset timing for more natural variation\n        $jit = rand(-1, 1) * $incr * $overlap;\n        ## Convert frequency to MIDI cents\n        $pitch = f2mc($freq);\n        ## Apply a random octave shift (in MIDI cents)\n        $octshift = random(-1, 4) * 1200;\n        ## Compute pitch difference and retune accordingly\n        $retune = pitchdiff($pitch, $pcs);\n        $freq *= c2r($retune + $octshift);\n        ## Randomize stereo panning\n        $pan = rand();\n        ## Generate a cycle-based waveform with the computed frequency and duration\n        cycle(@frequency $freq @duration $dur).transcribe(\n            ## Apply jittered onset time\n            @onset $onset + $jit\n            ## Apply random panning\n            @pan $pan\n            ## Apply amplitude envelope based on magnitude\n            @gain [0 $mag ** 2 0] [1 0 -0.66] \n        ) \n    ) \n);\n## Render the processed audio with normalization\nrender(\n    ## Apply normalization to -6 dB\n    @play 1 @process normalize(-6) \n)\n"})})]})}function p(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}}}]);