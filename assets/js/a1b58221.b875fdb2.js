"use strict";(self.webpackChunkbellplay_docs=self.webpackChunkbellplay_docs||[]).push([[3231],{341:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>u,frontMatter:()=>o,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"learning/tutorials/analysis","title":"14. Audio Descriptors","description":"One of the core features in bellplay~ is our ability to analyze buffers to extract relevant information.","source":"@site/docs/learning/tutorials/analysis.md","sourceDirName":"learning/tutorials","slug":"/learning/tutorials/analysis","permalink":"/docs/learning/tutorials/analysis","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":13,"frontMatter":{"sidebar_position":13,"title":"14. Audio Descriptors"},"sidebar":"tutorialSidebar","previous":{"title":"13. Inspecting Buffers","permalink":"/docs/learning/tutorials/bufferinspector"},"next":{"title":"15. Audio Descriptor Modes","permalink":"/docs/learning/tutorials/analysismodes"}}');var r=t(4848),i=t(8453);const o={sidebar_position:13,title:"14. Audio Descriptors"},a="Audio Descriptors",l={},c=[];function d(e){const n={code:"code",h1:"h1",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",...(0,i.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"audio-descriptors",children:"Audio Descriptors"})}),"\n",(0,r.jsxs)(n.p,{children:["One of the core features in ",(0,r.jsx)(n.strong,{children:"bellplay~"})," is our ability to analyze buffers to extract relevant information.\nThis is done via the ",(0,r.jsx)(n.code,{children:"analyze"})," function which, similar to 'process', allows us to perform multiple operations.\nIn the case of ",(0,r.jsx)(n.code,{children:"analyze"}),", these operations are known as audio descriptors, which we generate through functions.\nThese audio descriptors specify the different parameters for that specific operation, which ",(0,r.jsx)(n.code,{children:"analyze"})," takes as arguments.\nAs such, analyze outputs the analyze buffer with new keys, each associated with the specified descriptors."]}),"\n",(0,r.jsx)(n.p,{children:"This tutorial shows a simple use-case of audio analysis in bell:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsx)(n.li,{children:"First, we analyze a buffer to extract onset positions (i.e., transient times)."}),"\n",(0,r.jsx)(n.li,{children:"We use that information to compute the inter-onset durations \u2014 i.e., difference between consecutive onsets."}),"\n",(0,r.jsx)(n.li,{children:"Then we iterate through the onsets and durations to segment the original buffer, and analyze the loudness and spectral centroid of each segment."}),"\n",(0,r.jsx)(n.li,{children:"With this information, we generate sinusoidal oscillators that temporally coincide with transients in the initial buffer."}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["To learn about all available audio descriptors, please refer to the ",(0,r.jsx)(n.strong,{children:"bellplay~"})," reference documentation."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bell",metastring:'title="audio_descriptors.bell" showLineNumbers',children:"## generate buffer\n$buff = importaudio('drums.wav');\n## analyze buffer\n$buff = $buff.analyze(\n    ## use the onset detection descriptor\n    @descriptors onsets() \n);\n## extract onsets resulting from analysis\n$onsets = $buff.getkey('onsets');\n## compute inter-onset durations based on onsets\n$durations = ($onsets $buff.getkey('source_end')).x2dx();\n## iterate through onsets and durations\nfor $onset in $onsets, $dur in $durations do (\n    ## create buffer segment\n    $seg = $buff.setkey('offset', $onset).setkey('duration', $dur);\n    ## analyze buffer segment\n    $seg = $seg.analyze(\n        ## descriptor for loudness analysis\n        larm() \n        ## descriptor for spectral centroid (in Herz)\n        spectralcentroid() \n    );\n    ## extract analysis information for loudness and centroid\n    $larm = $seg.getkey('larm');\n    $centroid = $seg.getkey('spectralcentroid');\n    ## create gain envelope based on loudness feature\n    $env = [0 $larm 0] [1 0 -0.5];\n    ## generate and transcribe oscillator\n    cycle(\n        ## use centroid as frequency \n        @frequency $centroid\n        ## use inter-onset duration\n        @duration $dur\n    ).transcribe(\n        ## match segment onset\n        @onset $onset\n        ## apply gain envelope\n        @gain $env\n    ) \n);\n## transcribe original buffer to check accuracy of the analysis\n$buff.transcribe();\n## trigger rendering and normalize output\nrender(\n    @play 1 @process normalize() \n)\n"})})]})}function u(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>o,x:()=>a});var s=t(6540);const r={},i=s.createContext(r);function o(e){const n=s.useContext(i);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:o(e.components),s.createElement(i.Provider,{value:n},e.children)}}}]);