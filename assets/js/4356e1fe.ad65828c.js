"use strict";(self.webpackChunkbellplay_docs=self.webpackChunkbellplay_docs||[]).push([[7936],{8216:(e,s,r)=>{r.r(s),r.d(s,{assets:()=>t,contentTitle:()=>c,default:()=>a,frontMatter:()=>i,metadata:()=>n,toc:()=>d});const n=JSON.parse('{"id":"reference/audio-processing/process","title":"process","description":"process","source":"@site/docs/reference/audio-processing/process.md","sourceDirName":"reference/audio-processing","slug":"/reference/audio-processing/process","permalink":"/bellplay/docs/reference/audio-processing/process","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"hide_title":true},"sidebar":"tutorialSidebar","previous":{"title":"power","permalink":"/bellplay/docs/reference/audio-processing/power"},"next":{"title":"rampsmooth","permalink":"/bellplay/docs/reference/audio-processing/rampsmooth"}}');var o=r(4848),l=r(8453);const i={hide_title:!0},c=void 0,t={},d=[{value:"<code>process</code>",id:"process",level:2}];function p(e){const s={code:"code",em:"em",h2:"h2",hr:"hr",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,l.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(s.h2,{id:"process",children:(0,o.jsx)(s.code,{children:"process"})}),"\n",(0,o.jsx)(s.pre,{children:(0,o.jsx)(s.code,{className:"language-bell",children:"process(\n    @buffer ?  ## llll (required)\n    @operations ?  ## llll (required)\n    @prefade 0\n    @keepkeys null\n) -> llll\n"})}),"\n",(0,o.jsxs)(s.p,{children:["Applies a sequence of DSP operations to the input buffer, prior to rendering, via audio processing operations. These operations are generated through functions (e.g., see ",(0,o.jsx)(s.code,{children:"reverse"}),", ",(0,o.jsx)(s.code,{children:"paulstretch"}),", ",(0,o.jsx)(s.code,{children:"freeverb"}),", ",(0,o.jsx)(s.code,{children:"rubberband"}),"), which contain the parameters for that specific DSP operation. This results in a newly created buffer, with updated keys. To keep keys from the input buffer, such as keys associated with previous feature analyses, use the ",(0,o.jsx)(s.code,{children:"@keepkeys"})," argument by passing an optional list of keys. See ",(0,o.jsx)(s.code,{children:"@process"})," argument in ",(0,o.jsx)(s.code,{children:"render"}),"."]}),"\n",(0,o.jsx)(s.hr,{}),"\n",(0,o.jsxs)(s.p,{children:[(0,o.jsx)(s.strong,{children:"Arguments"}),":"]}),"\n",(0,o.jsxs)(s.ul,{children:["\n",(0,o.jsxs)(s.li,{children:[(0,o.jsx)(s.code,{children:"@buffer ?"})," [",(0,o.jsx)(s.em,{children:(0,o.jsx)(s.strong,{children:"llll"})}),"]: buffer to process. (",(0,o.jsx)(s.em,{children:"required"}),")"]}),"\n",(0,o.jsxs)(s.li,{children:[(0,o.jsx)(s.code,{children:"@operations ?"})," [",(0,o.jsx)(s.em,{children:(0,o.jsx)(s.strong,{children:"llll"})}),"]: list of audio process operations. (",(0,o.jsx)(s.em,{children:"required"}),")"]}),"\n",(0,o.jsxs)(s.li,{children:[(0,o.jsx)(s.code,{children:"@prefade"})," [",(0,o.jsx)(s.em,{children:(0,o.jsx)(s.strong,{children:"llll/null"})}),"]: optional pre-fade amount, in milliseconds."]}),"\n",(0,o.jsxs)(s.li,{children:[(0,o.jsx)(s.code,{children:"@keepkeys"})," [",(0,o.jsx)(s.em,{children:(0,o.jsx)(s.strong,{children:"symbol/list/null"})}),"]: optional list of keys to keep from input buffer."]}),"\n"]}),"\n",(0,o.jsx)(s.hr,{}),"\n",(0,o.jsx)(s.p,{children:(0,o.jsx)(s.strong,{children:"Output"})}),"\n",(0,o.jsxs)(s.p,{children:["processed buffer [",(0,o.jsx)(s.strong,{children:(0,o.jsx)(s.em,{children:"llll"})}),"]"]})]})}function a(e={}){const{wrapper:s}={...(0,l.R)(),...e.components};return s?(0,o.jsx)(s,{...e,children:(0,o.jsx)(p,{...e})}):p(e)}},8453:(e,s,r)=>{r.d(s,{R:()=>i,x:()=>c});var n=r(6540);const o={},l=n.createContext(o);function i(e){const s=n.useContext(l);return n.useMemo((function(){return"function"==typeof e?e(s):{...s,...e}}),[s,e])}function c(e){let s;return s=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:i(e.components),n.createElement(l.Provider,{value:s},e.children)}}}]);