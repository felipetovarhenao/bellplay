"use strict";(self.webpackChunkbellplay_docs=self.webpackChunkbellplay_docs||[]).push([[4303],{42499:e=>{e.exports=JSON.parse('{"tag":{"label":"render","permalink":"/docs/tags/render","allTagsPath":"/docs/tags","count":35,"items":[{"id":"learning/examples/resynthesis","title":"1. Audio Resynthesis","description":"A simple demonstration of granular quasi-resynthesis via partial tracks, where an sound is used to guide the behavior of sinusoidal grains.","permalink":"/docs/learning/examples/resynthesis"},{"id":"learning/tutorials/basicworkflow","title":"1. Basic Workflow","description":"In bellplay~, the basic building block of our scripts is the buffer.","permalink":"/docs/learning/tutorials/basicworkflow"},{"id":"learning/tutorials/bufferprocessing","title":"10. Buffer Processing","description":"One of the core features of bellplay~ is the ability to dynamically and flexibly apply chains of DSP algorithms to our buffers.","permalink":"/docs/learning/tutorials/bufferprocessing"},{"id":"learning/examples/temporalalignment","title":"10. Envelope-aware Temporal Alignment","description":"This example demonstrates how to align the envelopes of different audio samples based on their peak amplitude times.","permalink":"/docs/learning/examples/temporalalignment"},{"id":"learning/examples/keymaps","title":"11. Generating Keymaps","description":"This example automatically generates a custom keymap given a list of audio file paths:","permalink":"/docs/learning/examples/keymaps"},{"id":"learning/tutorials/postprocessing","title":"11. Post-rendering Processing","description":"Sometimes it can be more useful or desirable to apply processing to the entire output, instead of processing each buffer individually.","permalink":"/docs/learning/tutorials/postprocessing"},{"id":"learning/tutorials/export","title":"12. Exporting","description":"Although the bellplay~ graphical user-interface (GUI) allows us to export the final output of each script, it\'s sometimes useful being able to programmatically do the same through our scripts.","permalink":"/docs/learning/tutorials/export"},{"id":"learning/tutorials/audiocontrol","title":"13. Buffer-based Parameters","description":"This tutorial shows how to use buffers to control audio parameters.","permalink":"/docs/learning/tutorials/audiocontrol"},{"id":"learning/tutorials/bufferinspector","title":"14. Inspecting Buffers","description":"An essential part of writing code is being able to debug unwanted or unexpected behaviors.","permalink":"/docs/learning/tutorials/bufferinspector"},{"id":"learning/tutorials/analysis","title":"15. Audio Descriptors","description":"One of the core features in bellplay~ is our ability to analyze buffers to extract relevant information.","permalink":"/docs/learning/tutorials/analysis"},{"id":"learning/tutorials/analysismodes","title":"16. Audio Descriptor Modes","description":"When analyzing buffers, we can specify the output format for many of the available audio descriptors.","permalink":"/docs/learning/tutorials/analysismodes"},{"id":"learning/tutorials/features","title":"17. More Audio Features","description":"This tutorial provides an additional example for using buffer analysis features for audio processing.","permalink":"/docs/learning/tutorials/features"},{"id":"learning/tutorials/buildcorpus","title":"18. Audio corpora with SQL tables","description":"This tutorial demonstrates how to create an in-memory, queryable corpus of audio buffers by leveraging the createdbtable and querydb functions.","permalink":"/docs/learning/tutorials/buildcorpus"},{"id":"learning/tutorials/caching","title":"19. Caching Data","description":"In bellplay~, computation-heavy operations such as building large corpora, analyzing lots of audio data, and more, can be take a very long time, thus making it more tedious to experiment with our scripts every time we run them.","permalink":"/docs/learning/tutorials/caching"},{"id":"learning/examples/basicgranulation","title":"2. Basic Granulation","description":"An example of basic audio granulation, where short audio.","permalink":"/docs/learning/examples/basicgranulation"},{"id":"learning/tutorials/variables","title":"2. Variable Declarations","description":"When writing code, it\'s good practice to use descriptive variable names. For instance, noise to represent a noise signal, or saw for a sawtooth wave.","permalink":"/docs/learning/tutorials/variables"},{"id":"learning/tutorials/multirendering","title":"20. Multi-rendering","description":"This tutorial demonstrates a very simple but consequential feature in bellplay~ \u2014 namely, the ability to reuse rendered buffers multiple times to further refine and sculpt the final output into complex and intricate sounds.","permalink":"/docs/learning/tutorials/multirendering"},{"id":"learning/tutorials/sampling","title":"21. Basic Sampling","description":"In bellplay~, the ezsampler function provides a minimal but flexible interface for mapping symbolic pitch and velocity information to audio buffers.","permalink":"/docs/learning/tutorials/sampling"},{"id":"learning/tutorials/importingmidi","title":"22. Importing MIDI","description":"bellplay~ supports importing MIDI files (.mid or .midi) into our scripts, each described as a list of events.","permalink":"/docs/learning/tutorials/importingmidi"},{"id":"learning/tutorials/kdtree","title":"23. Feature-driven Sampling","description":"This tutorial shows how to build k-dimensional trees to efficiently perform feature-based search on buffers.","permalink":"/docs/learning/tutorials/kdtree"},{"id":"learning/tutorials/scoreconfig","title":"24. Score Formatting and Appearance","description":"Depending on what you\'re doing, you might want to have more control over what the score transcription looks like.","permalink":"/docs/learning/tutorials/scoreconfig"},{"id":"learning/examples/feedbacksynth","title":"3. Feedback Synthesis","description":"This code demonstrates a feedback-based synthesis technique, where buffers are routed back into their own processing chain to create a rich, evolving drone.","permalink":"/docs/learning/examples/feedbacksynth"},{"id":"learning/tutorials/importingaudio","title":"3. Importing Audio","description":"In bellplay~ we can also generate buffers by importing our own audio files into our scripts.","permalink":"/docs/learning/tutorials/importingaudio"},{"id":"learning/tutorials/transcription","title":"4. Transcription","description":"When transcribing buffers, we get to specify essential information about how each buffer fits within the final output.","permalink":"/docs/learning/tutorials/transcription"},{"id":"learning/examples/waveshaping","title":"4. Waveshaping Buffers","description":"A basic example of waveshaping in bellplay~, using a randomly generated breakpoint function.","permalink":"/docs/learning/examples/waveshaping"},{"id":"learning/examples/gliss","title":"5. Glissando texture","description":"An example of using time-varying resampling to generate a polyphonic texture.","permalink":"/docs/learning/examples/gliss"},{"id":"learning/tutorials/rendering","title":"5. Rendering","description":"Similar to the transcription stage, the rendering stage allows us to define important aspects about the final output.","permalink":"/docs/learning/tutorials/rendering"},{"id":"learning/tutorials/bufferkeys","title":"6. Buffer Keys","description":"As mentioned in earlier tutorials, buffers in bellplay~ are simply nested lists of key-value pairs.","permalink":"/docs/learning/tutorials/bufferkeys"},{"id":"learning/examples/markov","title":"6. Markov Music Generation","description":"This script illustrates how to construct and use an nth-order Markov model from MIDI data in bellplay~ for generative music.","permalink":"/docs/learning/examples/markov"},{"id":"learning/tutorials/markers","title":"7. Markers","description":"Sometimes it\'s useful to include markers in the transcription.","permalink":"/docs/learning/tutorials/markers"},{"id":"learning/examples/midiretuning","title":"7. MIDI Retuning","description":"An example of JI-based retuning of MIDI events.","permalink":"/docs/learning/examples/midiretuning"},{"id":"learning/tutorials/randomness","title":"8. Randomness","description":"Randomness is frequently used in algorithmic music to introduce variation and unpredictability. However, in many compositional workflows, reproducibility is just as important. In bellplay\\\\~, there are two types of random functions:","permalink":"/docs/learning/tutorials/randomness"},{"id":"learning/examples/temporalquantization","title":"8. Temporal Quantization","description":"A basic example of temporal quantization, where transient-based segments are temporally shifted to align with a rhythmic grid.","permalink":"/docs/learning/examples/temporalquantization"},{"id":"learning/examples/audiomosaic","title":"9. Audio Mosaicing","description":"An example of basic audio mosaicking in bellplay\\\\~, where a target audio file is reconstructed using segments drawn from a small audio corpus.","permalink":"/docs/learning/examples/audiomosaic"},{"id":"learning/tutorials/automation","title":"9. Automation","description":"In many cases, we will want to have some kind of DAW-style automation of certain parameters when generating or processing audio in our scripts.","permalink":"/docs/learning/tutorials/automation"}],"unlisted":false}}')}}]);