"use strict";(self.webpackChunkbellplay_docs=self.webpackChunkbellplay_docs||[]).push([[2418],{28453:(e,n,i)=>{i.d(n,{R:()=>s,x:()=>o});var t=i(96540);const r={},a=t.createContext(r);function s(e){const n=t.useContext(a);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:s(e.components),t.createElement(a.Provider,{value:n},e.children)}},67536:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>u,frontMatter:()=>s,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"learning/tutorials/analysismodes","title":"16. Audio Descriptor Modes","description":"When analyzing buffers, we can specify the output format for many of the available audio descriptors.","source":"@site/docs/learning/tutorials/analysismodes.md","sourceDirName":"learning/tutorials","slug":"/learning/tutorials/analysismodes","permalink":"/docs/learning/tutorials/analysismodes","draft":false,"unlisted":false,"tags":[{"inline":true,"label":"analyze","permalink":"/docs/tags/analyze"},{"inline":true,"label":"envelope","permalink":"/docs/tags/envelope"},{"inline":true,"label":"f2mc","permalink":"/docs/tags/f-2-mc"},{"inline":true,"label":"getkey","permalink":"/docs/tags/getkey"},{"inline":true,"label":"importaudio","permalink":"/docs/tags/importaudio"},{"inline":true,"label":"mc2f","permalink":"/docs/tags/mc-2-f"},{"inline":true,"label":"normalize","permalink":"/docs/tags/normalize"},{"inline":true,"label":"pitchdiff","permalink":"/docs/tags/pitchdiff"},{"inline":true,"label":"pitchmelodia","permalink":"/docs/tags/pitchmelodia"},{"inline":true,"label":"process","permalink":"/docs/tags/process"},{"inline":true,"label":"rampsmooth","permalink":"/docs/tags/rampsmooth"},{"inline":true,"label":"render","permalink":"/docs/tags/render"},{"inline":true,"label":"transcribe","permalink":"/docs/tags/transcribe"},{"inline":true,"label":"tri","permalink":"/docs/tags/tri"}],"version":"current","sidebarPosition":15,"frontMatter":{"sidebar_position":15,"title":"16. Audio Descriptor Modes","tags":["analyze","envelope","f2mc","getkey","importaudio","mc2f","normalize","pitchdiff","pitchmelodia","process","rampsmooth","render","transcribe","tri"]},"sidebar":"tutorialSidebar","previous":{"title":"15. Audio Descriptors","permalink":"/docs/learning/tutorials/analysis"},"next":{"title":"17. More Audio Features","permalink":"/docs/learning/tutorials/features"}}');var r=i(74848),a=i(28453);const s={sidebar_position:15,title:"16. Audio Descriptor Modes",tags:["analyze","envelope","f2mc","getkey","importaudio","mc2f","normalize","pitchdiff","pitchmelodia","process","rampsmooth","render","transcribe","tri"]},o="Audio Descriptor Modes",l={},c=[];function d(e){const n={code:"code",h1:"h1",header:"header",li:"li",p:"p",pre:"pre",ul:"ul",...(0,a.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"audio-descriptor-modes",children:"Audio Descriptor Modes"})}),"\n",(0,r.jsxs)(n.p,{children:["When analyzing buffers, we can specify the output format for many of the available audio descriptors.\nIn particular, there are 4 modes, which can be specified via the ",(0,r.jsx)(n.code,{children:"@mode"})," argument:"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"0"}),": global summary \u2014 i.e., one value for the entire buffer"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"1"}),": time series \u2014 i.e., a series of values, one for each frame."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"2"}),": time-tagged time series \u2014 same as with time series, but each frame tagged with its time position."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"3"}),": buffer \u2014 i.e., same as with time-series, but instead of a list, the result of the analysis is a buffer."]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"Note that not all descriptors support every mode, so make sure to check the documentation to learn more about each."}),"\n",(0,r.jsx)(n.p,{children:"In this tutorial, we perform monophonic pitch analysis on a buffer.\nThen, we manipulate the pitch information to perform diatonic transposition.\nThat information is then used to generate an envelope as a buffer, which in turn controls an oscillator.\nBoth the oscillator and the original buffer are transcribed."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bell",metastring:'title="audio_descriptor_modes.bell" showLineNumbers',children:"## import an audio file as a buffer\n$buff = importaudio('singing.wav');\n## analyze buffer\n$buff = $buff.analyze(\n    ## pitch analysis in time series mode\n    pitchmelodia(@mode 1) \n    ## set the analysis pitch unit to Hertz\n    @pitchunit 2\n);\n## extract pitch analysis (in Hertz)\n$frequencies = $buff.getkey('pitchmelodia');\n## modify pitch analysis information\n$frequencies = for $fq in $frequencies collect (\n    ## only modify positive frequency values \u2014 i.e., to avoid nan values\n    if $fq > 0 then (\n        ## convert frequency to midicents and transpose by a neutral 6th\n        $pitch = f2mc($fq) + 850;\n        ## adjust pitch to fit Dm scale and convert back to frequency\n        mc2f($pitch + $pitch.pitchdiff(0 2 4 5 7 9 10)) \n    ) else ($fq) \n);\n## create frequency envelope from pitch analysis as a buffer\n$freqenv = envelope(\n    @envelope $frequencies @duration $buff.getkey('duration') \n).process(\n    ## apply smoothing filter\n    rampsmooth() \n);\n## generate oscillator and transcribe\ntri(@frequency $freqenv).transcribe();\n## transcribe original buffer\n$buff.transcribe();\n## trigger rendering and normalize output\nrender(\n    @play 1 @process normalize() \n)\n"})})]})}function u(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}}}]);