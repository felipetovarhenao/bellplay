"use strict";(self.webpackChunkbellplay_docs=self.webpackChunkbellplay_docs||[]).push([[7637],{26856:e=>{e.exports=JSON.parse('{"tag":{"label":"cycle","permalink":"/docs/tags/cycle","allTagsPath":"/docs/tags","count":15,"items":[{"id":"learning/examples/resynthesis","title":"1. Audio Resynthesis","description":"A simple demonstration of granular quasi-resynthesis via partial tracks, where an sound is used to guide the behavior of sinusoidal grains.","permalink":"/docs/learning/examples/resynthesis"},{"id":"learning/tutorials/basicworkflow","title":"1. Basic Workflow","description":"In bellplay~, the basic building block of our scripts is the buffer.","permalink":"/docs/learning/tutorials/basicworkflow"},{"id":"learning/examples/temporalalignment","title":"10. Envelope-aware Temporal Alignment","description":"This example demonstrates how to align the envelopes of different audio samples based on their peak amplitude times.","permalink":"/docs/learning/examples/temporalalignment"},{"id":"learning/tutorials/audiocontrol","title":"13. Buffer-based Parameters","description":"This tutorial shows how to use buffers to control audio parameters.","permalink":"/docs/learning/tutorials/audiocontrol"},{"id":"learning/tutorials/bufferinspector","title":"14. Inspecting Buffers","description":"An essential part of writing code is being able to debug unwanted or unexpected behaviors.","permalink":"/docs/learning/tutorials/bufferinspector"},{"id":"learning/tutorials/analysis","title":"15. Audio Descriptors","description":"One of the core features in bellplay~ is our ability to analyze buffers to extract relevant information.","permalink":"/docs/learning/tutorials/analysis"},{"id":"learning/tutorials/scoreconfig","title":"24. Score Formatting and Appearance","description":"Depending on what you\'re doing, you might want to have more control over what the score transcription looks like.","permalink":"/docs/learning/tutorials/scoreconfig"},{"id":"learning/examples/feedbacksynth","title":"3. Feedback Synthesis","description":"This code demonstrates a feedback-based synthesis technique, where buffers are routed back into their own processing chain to create a rich, evolving drone.","permalink":"/docs/learning/examples/feedbacksynth"},{"id":"learning/tutorials/markers","title":"7. Markers","description":"Sometimes it\'s useful to include markers in the transcription.","permalink":"/docs/learning/tutorials/markers"},{"id":"learning/tutorials/automation","title":"9. Automation","description":"In many cases, we will want to have some kind of DAW-style automation of certain parameters when generating or processing audio in our scripts.","permalink":"/docs/learning/tutorials/automation"},{"id":"reference/buffer-generation/phasor","title":"phasor","description":"phasor","permalink":"/docs/reference/buffer-generation/phasor"},{"id":"reference/buffer-generation/rect","title":"rect","description":"rect","permalink":"/docs/reference/buffer-generation/rect"},{"id":"reference/buffer-generation/saw","title":"saw","description":"saw","permalink":"/docs/reference/buffer-generation/saw"},{"id":"reference/buffer-generation/tri","title":"tri","description":"tri","permalink":"/docs/reference/buffer-generation/tri"},{"id":"reference/buffer-generation/triangle","title":"triangle","description":"triangle","permalink":"/docs/reference/buffer-generation/triangle"}],"unlisted":false}}')}}]);