"use strict";(self.webpackChunkbellplay_docs=self.webpackChunkbellplay_docs||[]).push([[1913],{37316:e=>{e.exports=JSON.parse('{"tag":{"label":"rand","permalink":"/docs/tags/rand","allTagsPath":"/docs/tags","count":14,"items":[{"id":"learning/examples/resynthesis","title":"1. Audio Resynthesis","description":"A simple demonstration of granular quasi-resynthesis via partial tracks, where an sound is used to guide the behavior of sinusoidal grains.","permalink":"/docs/learning/examples/resynthesis"},{"id":"learning/examples/temporalalignment","title":"10. Envelope-aware Temporal Alignment","description":"This example demonstrates how to align the envelopes of different audio samples based on their peak amplitude times.","permalink":"/docs/learning/examples/temporalalignment"},{"id":"learning/examples/keymaps","title":"11. Generating Keymaps","description":"This example automatically generates a custom keymap given a list of audio file paths:","permalink":"/docs/learning/examples/keymaps"},{"id":"learning/tutorials/postprocessing","title":"11. Post-rendering Processing","description":"Sometimes it can be more useful or desirable to apply processing to the entire output, instead of processing each buffer individually.","permalink":"/docs/learning/tutorials/postprocessing"},{"id":"learning/tutorials/buildcorpus","title":"18. Audio corpora with SQL tables","description":"This tutorial demonstrates how to create an in-memory, queryable corpus of audio buffers by leveraging the createdbtable and querydb functions.","permalink":"/docs/learning/tutorials/buildcorpus"},{"id":"learning/tutorials/caching","title":"19. Caching Data","description":"In bellplay~, computation-heavy operations such as building large corpora, analyzing lots of audio data, and more, can be take a very long time, thus making it more tedious to experiment with our scripts every time we run them.","permalink":"/docs/learning/tutorials/caching"},{"id":"learning/examples/basicgranulation","title":"2. Basic Granulation","description":"An example of basic audio granulation, where short audio.","permalink":"/docs/learning/examples/basicgranulation"},{"id":"learning/tutorials/multirendering","title":"20. Multi-rendering","description":"This tutorial demonstrates a very simple but consequential feature in bellplay~ \u2014 namely, the ability to reuse rendered buffers multiple times to further refine and sculpt the final output into complex and intricate sounds.","permalink":"/docs/learning/tutorials/multirendering"},{"id":"learning/tutorials/sampling","title":"21. Basic Sampling","description":"In bellplay~, the ezsampler function provides a minimal but flexible interface for mapping symbolic pitch and velocity information to audio buffers.","permalink":"/docs/learning/tutorials/sampling"},{"id":"learning/tutorials/importingmidi","title":"22. Importing MIDI","description":"bellplay~ supports importing MIDI files (.mid or .midi) into our scripts, each described as a list of events.","permalink":"/docs/learning/tutorials/importingmidi"},{"id":"learning/tutorials/kdtree","title":"23. Feature-driven Sampling","description":"This tutorial shows how to build k-dimensional trees to efficiently perform feature-based search on buffers.","permalink":"/docs/learning/tutorials/kdtree"},{"id":"learning/examples/feedbacksynth","title":"3. Feedback Synthesis","description":"This code demonstrates a feedback-based synthesis technique, where buffers are routed back into their own processing chain to create a rich, evolving drone.","permalink":"/docs/learning/examples/feedbacksynth"},{"id":"learning/examples/waveshaping","title":"4. Waveshaping Buffers","description":"A basic example of waveshaping in bellplay~, using a randomly generated breakpoint function.","permalink":"/docs/learning/examples/waveshaping"},{"id":"learning/tutorials/markers","title":"7. Markers","description":"Sometimes it\'s useful to include markers in the transcription.","permalink":"/docs/learning/tutorials/markers"}],"unlisted":false}}')}}]);